{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ad714c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached tensorflow-2.8.0-cp38-cp38-win_amd64.whl (438.0 MB)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jvnganesh.acer-laptop.000\\anaconda3\\lib\\site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\jvnganesh.acer-laptop.000\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\jvnganesh.acer-laptop.000\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\jvnganesh.acer-laptop.000\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-13.0.0-py2.py3-none-win_amd64.whl (13.9 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp38-cp38-win_amd64.whl (895 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp38-cp38-win_amd64.whl (3.4 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jvnganesh.acer-laptop.000\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\jvnganesh.acer-laptop.000\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.1)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Collecting gast>=0.2.1\n",
      "  Using cached gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jvnganesh.acer-laptop.000\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.2-py2.py3-none-any.whl (156 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jvnganesh.acer-laptop.000\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\jvnganesh.acer-laptop.000\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\jvnganesh.acer-laptop.000\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jvnganesh.acer-laptop.000\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jvnganesh.acer-laptop.000\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jvnganesh.acer-laptop.000\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\jvnganesh.acer-laptop.000\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (4.0.0)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=1280956832e9c36fc19325a82fef0b1781a3077afed45ad71acee08e405ee124\n",
      "  Stored in directory: c:\\users\\jvnganesh.acer-laptop.000\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.0\n",
      "    Uninstalling importlib-metadata-3.10.0:\n",
      "      Successfully uninstalled importlib-metadata-3.10.0\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 importlib-metadata-4.11.3 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 markdown-3.3.6 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9589e538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.5.5.64-cp36-abi3-win_amd64.whl (35.4 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\jvnganesh.acer-laptop.000\\anaconda3\\lib\\site-packages (from opencv-python) (1.20.1)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.64\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349ff75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    def f(y_true, y_pred):\n",
    "        intersection = (y_true * y_pred).sum()\n",
    "        union = y_true.sum() + y_pred.sum() - intersection\n",
    "        x = (intersection + 1e-15) / (union + 1e-15)\n",
    "        x = x.astype(np.float32)\n",
    "        return x\n",
    "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
    "\n",
    "smooth = 1e-15\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fe82f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:35<00:00, 17.57s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.utils.generic_utils import CustomObjectScope\n",
    "#from tensorflow.python.keras.utils import CustomObjectScope\n",
    "#from metrics import dice_loss, dice_coef, iou\n",
    "'''\n",
    "from keras.utils import CustomObjectScope\n",
    "from keras.initializers import glorot_uniform'''\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\"\"\" Global parameters \"\"\"\n",
    "H = 512\n",
    "W = 512\n",
    "\n",
    "\"\"\" Creating a directory \"\"\"\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    \"\"\" Directory for storing files \"\"\"\n",
    "    create_dir(\"remove_bg\")\n",
    "\n",
    "    \"\"\" Loading model: DeepLabV3+ \"\"\"\n",
    "    #with CustomObjectScope({'GlorotUniform': glorot_uniform()}):\n",
    "     #   model = load_model('my_model.h5')\n",
    "    with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef, 'dice_loss': dice_loss}):\n",
    "        model = load_model(\"model.h5\", custom_objects={'iou': iou, 'dice_coef': dice_coef, 'dice_loss': dice_loss})\n",
    "\n",
    "    # model.summary()\n",
    "\n",
    "    \"\"\" Load the dataset \"\"\"\n",
    "    data_x = glob(\"images/*\")\n",
    "\n",
    "    for path in tqdm(data_x, total=len(data_x)):\n",
    "         \"\"\" Extracting name \"\"\"\n",
    "         name = path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "         \"\"\" Read the image \"\"\"\n",
    "         image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "         h, w, _ = image.shape\n",
    "         x = cv2.resize(image, (W, H))\n",
    "         x = x/255.0\n",
    "         x = x.astype(np.float32)\n",
    "         x = np.expand_dims(x, axis=0)\n",
    "\n",
    "         \"\"\" Prediction \"\"\"\n",
    "         y = model.predict(x)[0]\n",
    "         y = cv2.resize(y, (w, h))\n",
    "         y = np.expand_dims(y, axis=-1)\n",
    "         y = y > 0.5\n",
    "\n",
    "         photo_mask = y\n",
    "         background_mask = np.abs(1-y)\n",
    "\n",
    "         # cv2.imwrite(f\"remove_bg/{name}.png\", photo_mask*255)\n",
    "         # cv2.imwrite(f\"remove_bg/{name}.png\", background_mask*255)\n",
    "\n",
    "         # cv2.imwrite(f\"remove_bg/{name}.png\", image * photo_mask)\n",
    "         # cv2.imwrite(f\"remove_bg/{name}.png\", image * background_mask)\n",
    "\n",
    "         masked_photo = image * photo_mask\n",
    "         background_mask = np.concatenate([background_mask, background_mask, background_mask], axis=-1)\n",
    "         background_mask = background_mask * [0, 0, 255]\n",
    "         final_photo = masked_photo + background_mask\n",
    "         cv2.imwrite(f\"remove_bg/{name}.png\", final_photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517646b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
